
# -*- coding: utf-8 -*-
"""Train_Embedding_Colab.ipynb

Automatically generated by Colaboratory.

# Gender Classification: Embedding (InceptionResnetV1)
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
from tqdm import tqdm

# Install facenet-pytorch
os.system('pip install facenet-pytorch kagglehub tqdm')
from facenet_pytorch import InceptionResnetV1
import kagglehub

# Check device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Dataset
print("Downloading Dataset...")
dataset_path = kagglehub.dataset_download("cashutosh/gender-classification-dataset")
train_dir = os.path.join(dataset_path, 'Training')
val_dir = os.path.join(dataset_path, 'Validation')

# Transforms (FaceNet expects normalized to [-1, 1], usually 160x160)
transform = transforms.Compose([
    transforms.Resize((160, 160)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) 
])

train_dataset = datasets.ImageFolder(train_dir, transform=transform)
val_dataset = datasets.ImageFolder(val_dir, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Model
class EmbeddingClassifier(nn.Module):
    def __init__(self):
        super(EmbeddingClassifier, self).__init__()
        self.resnet = InceptionResnetV1(pretrained='vggface2')
        # Freeze ResNet
        for param in self.resnet.parameters():
            param.requires_grad = False
        
        self.fc = nn.Sequential(
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Linear(128, 2)
        )
        
    def forward(self, x):
        x = self.resnet(x) # Output is 512-dim embedding
        x = self.fc(x)
        return x

print("Loading InceptionResnetV1...")
model = EmbeddingClassifier().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)

# Train
epochs = 5
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    
    print(f"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}")
    
    # Validation
    model.eval()
    correct = 0; total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Validation Accuracy: {100 * correct / total:.2f}%")

# Save
save_path = 'gender_embedding.pth'
torch.save(model.state_dict(), save_path)
print(f"Saved to {save_path}")

try:
    from google.colab import files
    files.download(save_path)
except: pass
